\chapter{Previous Works}
\label{chap:prev}
\section{Various Goals and Evaluation}
The general goal of a computer expressive performance system is to generate expressive music, as opposed to the robotic and dull expression of rendered MIDI. Since the definition of "expressive" is very vague and ambiguous, each research needs to define a more precise and measurable goal. The followings are the most popular goals a computer expressive performance system aims to achieve:
\begin{enumerate}
   \item To perform musical notations in a non-robotic way (no specific style).
   \item To reproduce a human performance or a certain musician's style.
   \item To accompany a human performance.
   \item To validate a musicological theory of expressive performance.
   \item To directly render computer-composed musical works.
\end{enumerate}

Some systems try to perform musical notations in a non-robotic way in a general sense, without a certain style in mind. These systems have been employed in music typesetting softwares, like Finale \cite{finale} and Sibelius \cite{sibelius}, to play the notation expressively. Most systems will implicitly include this goal.
%TODO:discuss the goals

Systems that are designed to reproduce certain human performance or style are usually designed and trained using a particular performer's recordings. One commercial example is the Zenph re-performance CD \cite{zenph}. This CD is a reconstruction of Rachmaninov's recording archives. By analysing various performance parameters like timing and key pressure, the low quality audio archives are re-synthesized on a modern computer controlled piano. If we push this idea further, we may be able to learn a performance model of Rachmaninov and perform musical pieces that Rachmaninov himself never recorded in his lifetime.%contains music performed by an expressive performance model of Rachimaninov's style, but Rachimaninov had never recorded these pieces in his lifetime. 


Accompaniment systems try to render expressive music that acts as an accompaniment for a human performance. The challenge is that the system must be able to track the progress of the human performance and adaptively render the accompaniment in real-time. One commercial example is Cadenza \cite{cadenza}, using the technology created by Christopher Raphel. It can track the soloist's performance and play the accompanying orchestral part accordingly.


Another goal is to validate musicological theories. Musicologists may propose theories on how music are performed expressively, by building a generative model, they can validate their theories. These systems may focus more on the specific phenomenon that the theory tries to explain instead of generating music that is pleasant to human. 


Finally, some systems combine computer composition technology with expressive performance technology. These systems have a big advantage because the intention of the composer can be shared with the performer. Other systems that perform past compositions can only guess the composers' intentions by analyzing the score notations. These systems usually have their own data structures to represent music, which contain more information than traditional music notations, but the performance system is not backward compatible with past compositions.


Because of the high diversity in the goals they want to achieve, it is very hard to make fair comparisons between systems. But we can still evaluate the capabilities of these systems by the following three key indicators proposed by \cite{THEBOOK}:
\begin{enumerate}
   \item Expressive expression capability
   \item Polyphonic capability
   \item Performance creativity
\end{enumerate}

Expressive expression capability range from high-level structural expressions (e.g. tempo contrast between sections) to note-level expressions (e.g. onset, loudness, duration) or even sub-note expressions (e.g. loudness envelope, timbre). Most systems can generate note-level expressions, but higher or lower level expressions are much rare.

Polyphonic capability indicates weather the system can perform polyphonic input. Polyphonic systems are more challenging than monophonic ones because they require synchronization between voices. 

Performance creativity measures the ability of the system to create novel expressions. The desired level of creativity varies from goal to goal. A system aiming to recreate human performances may want to produce deterministic expressions based on the learned knowledge, while a system that is combined with a composition system may want to create highly novel performance. 


%The goals discussed above imply different level of musical creativity. Huamn performance reproduction requires mimicry over creativity, on the other hand, system that plays its own composition can have a large range of creativity to explore. The methods employed also limits the ability of creativity, which will be discussed in the next section.
%Each system
Each system will design different experiments and metrics to verify their goals. Thus, the self-reported results can hardly be compared. The only public contest that evaluates expressive performance systems is RenCon (Performance Rendering Contest)\cite{RenCon}. Scores (MIDI) will be given to participants one hour before the competition starts. The participants must generate the expressive version of the MIDIs in the given time; and the MIDIs will be played live on a Yamaha Disklavier piano. The audience and a jury consisting of professional musicians will give ratings for each performance. The performances are arranged in random, so the audience and jury will not know which participant is behind each performance.

The RenCon is divided into fully automatic and semi-automatic categories. Since the degree of human intervention in the semi-automatic category varies widely between systems, it is not very fair to compare them.



%\framebox{TODO: Discuss works that focus on timber only, e.g. Prof. Su's violin work}
%Each system
\section{Researches Classified by Methods Used}
%\begin{table}
%   \centering
%   \begin{tabular}{|c|c|}
%      TBD & TBD\\
%      TBD & TBD\\
%   \end{tabular}
%   \caption{List of Reviewed Systems}
%   \label{tab:prevworks}
%\end{table}
Despite the differences between goals of different expressive performance systems, all expressive performance systems must have some strategies to learn and apply performance knowledge. There are generally two approaches: rule-based or machine-learning-based.

Using rules to generate expressive music is probably the earliest approach. Director Musices \cite{17} is one of the early example.  Pop-E \cite{28} is also a rule-based system which can generate polyphonic music, using its voice synchronization algorithm. Computational Music Emotion Rule System \cite{31} tries to develop rules that express human emotions. Other systems like Hierarchical Parabola System \cite{17,18,19,20}, Composer Pulse System \cite{21,22}, Bach Fugue System \cite{23}, Trumpet Synthesis System \cite{24, 25} and Rubato \cite{26, 27} are also some examples. Most of the rule-based systems focus on expressive attributes like note onset, note duration and loudness, but Hermode Tuning System \cite{29} puts special emphasis on intonation. Rule-based systems are generally more computationally efficient because the mathematical model is much simpler than those learned by machine learning algorithms. And rules are generally more understandable to human than complex model parameters. Some of the nuances, such as subconscious deviations, may be hard to describe by rules, so there is empirical limit on how complex the rule-based system can be. The lack of creativity is also a problem for rule-based approach.

Another approach is to acquire performance knowledge by machine learning. Many machine learning methods have already been applied to this problem. For example, Music Interpretation System \cite{32,33,34} and CaRo \cite{35,36,37} both use linear regression to learn performance knowledge. However, it is very unlikely that the expressive performance problem can be generated from a linear system, and therefore Music Interpretation System tries to introduce non-linearity by using logic AND operations on linear regression results. But generally speaking, linear regression is too simple to capture the core of expressive performance.

More complicated machine-learning algorithms have also been applied: ANN Piano \cite{38} and Emotional flute \cite{39} use artificial neural network. ESP Piano \cite{55} and Music Plus One \cite{52,53,54} use statistical graphical models such as hidden Markov model (HMM) and Bayesian belief network, but they did not use structural support vector machine to train the HMM. KCCA Piano System \cite{57} uses kernel regression. Drumming System \cite{82} tries different mapping models that generate drum patterns.

Evolutionary computation such as genetic programming is used in Genetic Programming Jazz Sax \cite{88}, Sequential Covering Algorithm Genetic Algorithm \cite{59}, Generative Performance Genetic Algorithm \cite{89} and Multi-Agent System with Imitation \cite{60, 93}. Evolutionary computation requires long training time, and the results are less predictable. But being unpredictable also means that these systems will create interesting performances in an unconventional way.

Another possible approach is to use case-based reasoning. SaxEx \cite{40,41,42} use fuzzy rules based on emotions to generate Jazz saxophone performance. Kagurame \cite{43,44} focus on style (Baroque, Romantic, Classical etc.) instead of emotion. Ha-Hi-Hun \cite{45} has a more ambitious goal in mind: to accept natural language instructions like \enquote{Perform piece X in the style of Y.} Another series of researches done by Widmer et al., the PLCG \cite{46, 47, 48}, use data mining technique to find rules for expressive performance. Its successor -- Phrase-decomposition/PLCG \cite{49} -- adds hierarchical phrase structures capability to the original PLCG system. And the latest research in the series -- DISTALL \cite{50, 51} -- adds hierarchical rules to the original one.

Most of the performance systems discussed above take musical notation (MusicXML, MIDI, etc.) or inexpressive audio as input. They have to figure out the expressive intention of the composer by analyzing the score. Another type of computer expressive performance has a big advantage over the ones previous described, by combining computer composition and expressive performance, the performance module can receive the composition intention directly from the composition module. Ossia \cite{61} and pMIMACS \cite{pmimacs} are two examples of this category. This approach provides great possibilities for creativity, but such systems can only play their own composition, which limits its range of application.

%\framebox{TODO:Fig.:selected figures from previous works}
\section{Additional Specialties}

Most expressive performance systems implicitly or explicitly generate piano performances, because it is relatively easy to collect training samples for piano, and the piano sound is relatively easy to synthesize. Yet, some systems generate music on other instruments, such as the saxophone \cite{40, 41, 42}, trumpet \cite{24, 25}, flute \cite{39} and drums \cite{56}. These systems require extra efforts in creating instrument-specific models for training, generation and synthesizing. Y.-H Kuo et al. \cite{profsu} also proposed a way to re-synthsize individual notes into a performance with smooth timbre variation, but the work focus more on sub-note level timbre synthesis.

%\framebox{TODO: Discuss works that focus on timber only, e.g. Prof. Su's violin work}

If not specified, most systems handle traditional Western tonal music. However, most saxophone-based work \cite{40, 41, 42} generates Jazz music, because saxophone is an iconic instrument in Jazz performance. And the Drumming System \cite{56} generates Brazilian drumming music.%The Bach Fugue System \cite{23}, literally, focus on fugue works composed by bach. 

Performing polyphonic music is much more challenging than monophonic music because it requires synchronization between voices. Pop-E \cite{28} uses a synchronization mechanism to achieve polyphonic performance. Bach Fugue System \cite{23} is created using the polyphonic rules in music theory on fugue, so it is inherently able to play polyphonic fugues. KCCA Piano System \cite{57} can generate homophonic music -- an upper melody with an accompaniment -- which is common in the piano music.  Music Plus One \cite{52,53,54} is a little bit different because it is a accompaniment system, and it adapts non-expressive orchestral accompaniment track to the user's performance. %Other systems usually generates monophonic tracks only. 

