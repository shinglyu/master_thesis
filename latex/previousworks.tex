\chapter{Previous Works}
\label{chap:prev}
\section{Various Goals and Evaluation}
The general goal of a computer expressive performance system is to generate expressive music, as opposed to the robotic and dull expression of rendered MIDI. But the definition of "expressive" is very vague and ambiguous, so each research will need to define a more precise and measurable goal. The following are the most popular goals a computer expressive performance system wants to achieve:
\begin{enumerate}
   \item Perform music notations in a non-robotic way (no specific style).
   \item Reproduce a human performance or a certain musician's style.
   \item Accompany a human performance.
   \item Validate a musicological theory of expressive performance.
   \item Directly render computer-composed music works.
\end{enumerate}

Some systems try to perform music notations in a non-robotic way in a general sense, without a certain style in mind. These systems has been employed in music typesetting softwares, like Finale \cite{finale} and Sibelius \cite{sibelius}, to play the notation expressively. Most systems will implicitly include this goal.
%TODO:discuss the goals

Systems that are designed to reproduce certain human performance or style are usually designed and trained using a particular performer's recordings. One commercial example is the Zenph re-performance CD \cite{zenph}. This CD contains music performed by an expressive performance model of Rachimaninov's style, but Rachimaninov had never recorded these pieces in his lifetime. 


Accompaniment systems try to render expressive music that act as an accompaniment for a human performance. The challenge is that the system must be able to track the progress of a human performance and adaptively render the accompaniment in real-time. One commercial example is Cadenza \cite{cadenza}, using the technology created by Christopher Raphel. It can track the soloist's performance and play the accompaniment orchestral part accordingly.


Another goal is to validate musicological theories. Musicologist may propose theories on expressive music performance, by building a generative model, they can validate their theories. These systems may focus more on the specific phenomenon that the theory tries to explain instead of generating music that is pleasant to human. 


Finally, some systems combines computer composition with expressive performance. These systems have a big advantage because the intention of the composer can be shared with the performer. Other systems that performs past compositions can only guess the composer's intention by analyzing the score notation. These systems usually has their own data structure to represent music, which can contain more information than traditional music notation, but the performance system is not backward compatible with past compositions.


Because of the high diversity in the goals they want to achieve, it is very hard to make fair comparison between systems. But we can still evaluate the capability of these systems by the following three key indicators proposed by \cite{THEBOOK}:
\begin{enumerate}
   \item Expressive expression capability
   \item Polyphonic capability
   \item Performance creativity
\end{enumerate}

Expressive expression capability can range from very high level structural expression (e.g. tempo contrast between sections) to note level expression (e.g. onset, loudness, duration) or even sub-note expression (e.g. loudness envelop, timbre). Most systems can generate note-level expression, but higher or lower level expressions are much rare.

Polyphonic capability indicates if the system can perform polyphonic input. Polyphonic systems are more challenging than monophonic ones because they requires synchronization between voices. 

Performance creativity measures the ability of the system to create novel expression. The desired level of creativity varies from goal to goal. A system aiming to recreate human performance may want to produce deterministic expressions based on the learning material, while a system that is combined with a composition system may want to create highly novel performance. 


%The goals discussed above imply different level of musical creativity. Huamn performance reproduction requires mimicry over creativity, on the other hand, system that plays its own composition can have a large range of creativity to explore. The methods employed also limits the ability of creativity, which will be discussed in the next section.
%Each system
Each system will design different experiment and metrics to verify their goals. Thus, the self-reported results are can hardly be compared. The only public contest that evaluates expressive performance systems is called RenCon (Performance Rendering Contest)\cite{RenCon}. Scores (MIDI) will be given to participants one hour before the competition starts. The participants must generate the expressive version of the MIDIs in the given time, the MIDIs will be played live on a Yamaha Disklavier piano. The audience and a jury cosists of professional musicians will give ratings for each performance. The performances are played in random order, so the audience and jury won't know which participant is behind each performance.

The RenCon is divided into fully automatic and semi-automatic categories. But the degree of human intervention in the semi-automatic category varies widely between systems. So it's not very fair to compare them.



%\framebox{TODO: Discuss works that focus on timber only, e.g. Prof. Su's violin work}
%Each system
\section{Researches Classified by Methods Used}
%\begin{table}
%   \centering
%   \begin{tabular}{|c|c|}
%      TBD & TBD\\
%      TBD & TBD\\
%   \end{tabular}
%   \caption{List of Reviewed Systems}
%   \label{tab:prevworks}
%\end{table}
Despite the difference between goals of different expressive performance systems, all expressive performance systems must have some strategy to learn and apply performance knowledge. There are generally two approach: rule-based or machine-learning-based.

Using rules to generate expressive music is probably the earliest approach. Director Musices \cite{17} is one of the early example.  Pop-E \cite{28} is also a rule-based system which can generate polyphonic music, using its voice synchronization algorithm. Computational Music Emotion Rule System \cite{31} tried to develop rules that express human emotions. Other systems like Hierarchical Parabola System \cite{17,18,19,20}, Composer Pulse System \cite{21,22}, Bach Fugue System \cite{23}, Trumpet Synthesis System \cite{24, 25} and Rubato \cite{26, 27} are also some examples. Most of the rule-based systems focus on expressive attributes like note onset, note duration and loudness, but Hermode Tuning System \cite{29} put special emphasis on intonation. Rule-based systems are generally more computationally efficient because the mathematical model is much simple than those learned by machine learning algorithms. And rules are generally more understandable to human than complex model parameters. But some of the nuance, such as some subconscious deviation, may be hard to describe by rules, so there is a emperical limit on how complex the rule-based system can be. Lack of creativity is also a problem for rule-based approach.

Another approach is to acquire performance knowledge by machine learning. Many machine learning methods have already been applied to this problem. For example, Music Interpretation System \cite{32,33,34} and CaRo \cite{35,36,37} both use linear regression to learn performance knowledge. But it is very unlikely that the expressive performance problem is a linear system, so Music Interpretation System try to introduce non-linearity by using logic AND operations on linear regression results. But generally speaking, linear regression is too simple to capture the core of expressive performance.

More complicated machine-learning algorithms have also been applied: ANN Piano \cite{38} and Emotional flute \cite{39} uses artificial neural network. ESP Piano \cite{55} and Music Plus One \cite{52,53,54} uses statistical graphical models such as hidden Markov model (HMM) and Bayesian belief network, but they did no use structural support vector machine to train the HMM.%, although the later one focus more on accompaniment task rather than rendering notation. 
 KCCA Piano System \cite{57} uses kernel regression. Drumming System \cite{82} tried different mapping models that generates drum patterns.

Evolutionary computation such as genetic programming is used in Genetic Programming Jazz Sax \cite{88}, Sequential Covering Algorithm Genetic Algorith \cite{59}, Generative Performance Genetic Algorithm \cite{89} and Multi-Agent System with Imitation \cite{60, 93}. Evolutionary computation takes long training time, and the results are less predictable. But being unpredictable also means that these systems can create interesting performances in an unconventional way.

Another possible approach is to use case-based reasoning. SaxE \cite{40,41,42} use fuzzy rules based on emotions to generate Jazz saxophone performance. Kagurame \cite{43,44} focus on style (Baroque, Romantic, Classic etc.) instead of emotion. Ha-Hi-Hun \cite{45} has a more ambitions goal in mind: to accept natural language instructions like \enquote{Perform piece X in the style of Y.} Another series of researches done by Widmer at el., called PLCG \cite{46, 47, 48}, uses data mining technique to find rules for expressive performance. It's successor -- Phrase-decomposition/PLCG \cite{49} added hierarchical phrase structures support to the original PLCG system. And the latest research in the series called DISTALL \cite{50, 51} added hierarchical rules to the original one.

Most of the performance systems discussed above takes musical notation (MusicXML, MIDI, etc.) or inexpressive audio as input. They have to figures out the expressive intention of the composer by analyzing the score. But another type of computer expressive performance has a big advantage over the previous described ones, by combining computer composition and expressive performance, the performance module can receive the composition intention directly from the composition module. Ossia \cite{61} and pMIMACS \cite{pmimacs} are two examples of this category. This approach provides great possibility for creativity, but they can only play their own composition, which limits it range of application.

%\framebox{TODO:Fig.:selected figures from previous works}
\section{Additional Specialties}

Most expressive performance systems implicitly or explicitly generate piano performance, because it's relatively easy to collect training samples for piano, and piano sound is relatively easy to synthesize. Yet, some systems generate music in other instruments, such as saxophone \cite{40, 41, 42}, trumpet \cite{24, 25}, flute \cite{39} and drums \cite{56}. These systems requires extra effort in creating instrument models in training, generation and synthesizing. Y.-H Kuo et al. \cite{profsu} also propsed a way to re-synthsize individual notes into a performance with smooth timbre variation, but the work focus more on sub-note level timbre systhsis.

%\framebox{TODO: Discuss works that focus on timber only, e.g. Prof. Su's violin work}

If not specified, most systems handles traditional western tonal music. However, most saxophone-based work \cite{40, 41, 42} generates Jazz music, because saxophone is an iconic instrument in Jazz performance. And the Drumming System \cite{56} generates Brazilian drumming music.%The Bach Fugue System \cite{23}, literally, focus on fugue works composed by bach. 

Performing polyphonic music is much more challenging than monophonic music, because it requires synchronization between voices. Pop-E \cite{28} use a synchronization mechanism to achieve polyphonic performance. Bach Fugue System \cite{23} is created using the polyphonic rules in music theory about fugue, so it's inherently able to play polyphonic fugue. KCCA Piano System \cite{57} can generate homophonic music -- an upper melody with an accompaniment -- which is common in piano music.  Music Plus One \cite{52,53,54} is a little bit different because it's a accompaniment system, it adapts non-expressive orchestral accompaniment track to user's performance. %Other systems usually generates monophonic tracks only. 

