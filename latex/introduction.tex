\chapter{Introduction}
\section{Motivation}
%Robot => speech => MIDI (history)
%From the mechanical music performing automata, to the Japanese virtual signer Hatune Miku, there had been many attempts to create automated system that performs music. However, many of these system can only perform predefined expression, which is not very satisfying. State-of-the-art text-to-speech system can already generate fluid and natural speech, but computer performance still can't perform very expressively.
From the mechanical music performing automata of the middle ages, to the latest Japanese virtual signer Hatune Miku, there have been many attempts to create automated systems that perform music. However, many of these systems can only generate predefined expression. State-of-the-art text-to-speech system can already generate fluid and natural speech, but computer performance still can't perform very expressively. Therefore, many researchers have devoted their efforts to develop systems that can automatically or semi-automatically perform music expressively. There is even a biannual contest for such systems called the Music Performance Rendering Contest (RenCon)\cite{RenCon}. The RenCon roadmap suggests that by 2050, they wish that a computer performer can win the International Chopin Piano Contest.

%Therefore, many researcher have devoted many effort to develop systems that can automatically or semi-automatically perform music expressively. There is even a biannual contest called Music Performance Rendering Contest (RenCon)\cite{RenCon} that puts all performance system to into competition. Their roadmap suggest that they wish to win the Chopin International Piano Contest by a computer performer. We will review previous works, including many which won the RenCon prizes, in Chapter \ref{chap:prev}.
%Computer generated music, such as synthsized MIDI, are often considered robotic and unexpressive. But we have already witnessed the fluid and lively sound generated by state-of-the-art text-to-speech systems. This inspired us to develop a system that can read a music score and play it in an expressive, humanly way. Such system can be used for audiolizing score notation editing software, creating interactive media content, and generating royality-free music. 

%Established pianists always has his/her own distinctive style. Such style distinguished himself/herself from all the other pianists. If the expressive performance system can learn the style of a performer, it might be able to provide musicological insight of performance styles. Furthermore, we can even make a maestro who is no longer with us play music he/she never played in his/her lifetime.

There are many potential applications for a computer expressive performance system; many commercial music typesetting softwares like Finale\cite{finale} and Sibelius\cite{sibelius} already have expressive playback features built-in. For the entertainment industry, such systems provide personalized music listening experience. For the music production industry, this technology should save a lot of cost on hiring musicians and paying license fees. Such a system also opens up new opportunities in art, such as human-machine co-performance or interactive multimedia installation. In academia, researchers can use this technology to study the performance style of musicians, or restore historical recording archive.


%\begin{figure}[tp]
%   \begin{center}
%      %TODO:Fig.: expressive performance concept
%      \includegraphics[width=\textwidth]{fig/TBDFigure}
%
%   \end{center}
%   \caption{From Composer to Performance}
%   \label{fig:concept}
%\end{figure}
%Application: musicology study, typesetting tool, play score archive, play computer-generated music, accompaniment



\section{Goal and Contribution}
%\framebox{TODO:brief guide to previous works}
The ultimate goal of this paper is to be able to play any music in any expressive style specified. However, due to technical and time constrains, we narrow down our goal to building a computer expressive performance system that performs monophonic musical phrases by off-line supervised learning. The phrasings need to be annotated by human, so it is a semi-automatic system.
%The ultimate goal of this paper is to be able to play any music in any expressive style specified. But due to the technical and time constrain, we need to set a more practical goal for our research. We wish to build a computer expressive performance system based on an off-line supervised learning algorithm. The system will be able to learn any play monophonic musical phrases. The expressiveness will be at phrase level, structural or timbre related expression are not the primary concern. The performance style will be controlled by the learning material, which is traditional music notation, with human-annotated phrasing information. If only recordings from a single performer is given, it should learn the particular style of the performer.


The major contribution of this paper is that we apply the structural support vector machine on the expressive performance problem. There exists no previous work that uses the discriminative learning power of structural support vector machine with hidden Markov model output (SVM-HMM) on the computer expressive performance question. We also developed methods and tools to generate an expressive performance corpus.
%\framebox{TODO: normalization and quantization solution}
%\bibliographystyle{unsrt}
%\bibliography{thesisbib}
\section{Chapter Organization}
In Chapter \ref{chap:prev}, we will give an overview of previous works and their varying goals. These works will be grouped by way of how they learn performance knowledge, and we will discuss some additional specialities such as special instrument models or special user interaction patterns. In Chapter \ref{chap:proposed}, we will first give a brief introduction to the mathematical background of SVM-HMM, and then give a top-down explanation to the proposed method. In Chapter \ref{chap:corpus}, we will explain how the corpus used for training is designed and implemented. In Chapter \ref{chap:exp}, we will discuss several experiments that demostrate design trade-offs and the subjective test results. Finally, we have included an appendix that presents some software tools used in this research, which may be helpful for other researchers in the field of computer music.
%\framebox{REVIEW1}
