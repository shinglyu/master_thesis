@article{Mazzola1994,
author = {Mazzola, G and Zahorka, O},
journal = {Computer Music Journal},
number = {1},
pages = {40--52},
title = {{Tempo curves revisited: Hierarchies of performance fields}},
url = {http://www.jstor.org/stable/3680521},
volume = {18},
year = {1994}
}
@book{Mazzola2002,
address = {Basel/Boston},
author = {Mazzola, Guerino},
isbn = {3764357312},
publisher = {Birkh\"{a}user},
title = {{The Topos of Music: Geometric Logic of Concepts, Theory, and Performance}},
url = {http://www.amazon.com/The-Topos-Music-Geometric-Performance/dp/3764357312},
year = {2002}
}
@inproceedings{Dannenberg1998,
address = {Ann Arbor, Michigan},
author = {Dannenberg, Roger and Pellerin, Hank and Derenyi, Itsvan},
booktitle = {Proceedings of the 1998 international computer music conference},
editor = {1998, October},
pages = {57--61},
publisher = {International Computer Music Association},
title = {{A Study of Trumpet Envelopes}},
url = {http://repository.cmu.edu/compsci/501},
year = {1998}
}
@article{Dannenberg1998a,
abstract = {Abstract Convincing synthesis of wind instruments requires more than the reproduction of individual tones. Since the player exerts continuous control over amplitude, frequency, and other parameters, it is not adequate to store simple templates for individual tones and string them together to make phrases. Transitions are important, and the details of a tone are affected by context. To address these problems, we present an approach to music synthesis that relies on a performance model to generate musical control signals and an instrument model to generate appropriate time?varying spectra. This approach is carefully designed to facilitate model construction from recorded examples of acoustic performances. We report on our experience developing a system to synthesize trumpet performances from a symbolic score input.
Abstract Convincing synthesis of wind instruments requires more than the reproduction of individual tones. Since the player exerts continuous control over amplitude, frequency, and other parameters, it is not adequate to store simple templates for individual tones and string them together to make phrases. Transitions are important, and the details of a tone are affected by context. To address these problems, we present an approach to music synthesis that relies on a performance model to generate musical control signals and an instrument model to generate appropriate time?varying spectra. This approach is carefully designed to facilitate model construction from recorded examples of acoustic performances. We report on our experience developing a system to synthesize trumpet performances from a symbolic score input.},
author = {Dannenberg, Roger B. and Derenyi, Istvan},
doi = {10.1080/09298219808570747},
issn = {0929-8215},
journal = {Journal of New Music Research},
month = sep,
number = {3},
pages = {211--238},
publisher = {Routledge},
title = {{Combining instrument and performance models for high‚Äêquality music synthesis}},
url = {http://dx.doi.org/10.1080/09298219808570747},
volume = {27},
year = {1998}
}
@article{Johnson1991,
abstract = {The development and implementation of an expert system that determines the tempo and articulations of Bach fugues are described. The rules in the knowledge base are based on the expertise of two professional performers. The system's input is a numeric representation of the fugue. The system processes the input using a transition graph, a data structure consisting of nodes where data is stored and edges that connect the nodes. The transition graph recognizes rhythmic patterns in the input. Once the system identifies a pattern, it applies a specific rule or performs a procedure. System output consists of a listing of tempo and articulation instructions. To validate the expert system, its output was compared with versions of fugues edited by one of the two experts used in developing the system. In tests with six fugues, the expert system generated the same editing instructions 85 to 90\% of the time.},
annote = {23

      },
author = {Johnson, M.L.},
doi = {10.1109/2.84832},
issn = {0018-9162},
journal = {Computer},
month = jul,
number = {7},
pages = {30--34},
shorttitle = {Computer},
title = {{Toward an expert system for expressive musical performance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=84832},
volume = {24},
year = {1991}
}
